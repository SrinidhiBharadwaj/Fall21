{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a38dd0a",
   "metadata": {},
   "source": [
    "# Srinidhi Bharadwaj Kalgundi Srinivas\n",
    "# A59010584\n",
    "\n",
    "# Assignment - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed20a9f",
   "metadata": {},
   "source": [
    "__Attached below is the curve for probability of error as a function of alpha where alpha ranges from [1e-4, 1e4].__\n",
    "\n",
    "![Figure: 1 - Probability of error as a function of alpha](Question-a.png)\n",
    "\n",
    "__a) For Bayesian Parameter Estimation, mean of the posterior is governed by the covariance which in turn is governed by the alpha value. As the alpha value increases, mean of the posterior moves towards the mean of the MLE solution which is clearly observed from the graph below. This causes the probability of error to increase to a certain point and saturate after a certain value of alpha__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48420888",
   "metadata": {},
   "source": [
    "__b) Graph for probability of error as a function of alpha is for ML estimates are as shown in Figure: 1.__\n",
    "__Graph is a straight line horizontail to the alpha axis as the ML estimates do not depend on the values of alpha and depends only on the mean and covariances of the dataset.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26cfb58",
   "metadata": {},
   "source": [
    "#### MAP estimate for the mean\n",
    "\n",
    "__c) Probability of errors as a function of alpha for the MAP estimates of the mean are shown in Figure: 1. Since MAP estimate shares the mean with Bayesian parameter estimation, probability of error is small when alpha is small and increase as alpha increases. Value of POE for MAP is slightly larger than that of the Bayesian parameter estimation as contribution of the prior covariance is smaller for MAP,__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e80d6",
   "metadata": {},
   "source": [
    "# Quiz - d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c877d6",
   "metadata": {},
   "source": [
    "__Attached below is the curve for probability of error as a function of alpha for strategy 1 for D1, D2, D3 and D4 datasets__\n",
    "\n",
    "![Figure: 2 - Probability of error as a function of alpha for Strategy 1 for all datasets](Strategy-1.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d2785",
   "metadata": {},
   "source": [
    "### Change in behavior among different datasets:\n",
    "\n",
    "__It could be observed that in dataset one, Bayes predictive model is obviously performed better\n",
    "than ML and MAP. In dataset two, Bayes predictive model performed worse than\n",
    "ML and MAP. In datasets three and four, Bayes predictive model just performs slightly better\n",
    "than ML and MAP. This is because different datasets have different prior information for mean and the covariance.\n",
    "Size of datasets play an important role in determining the mean and covariances. As the size of the dataset increases, the mean and covariance estimation move towards the ML estimates.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da408bb",
   "metadata": {},
   "source": [
    "## e) Strategy-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6d121",
   "metadata": {},
   "source": [
    "__Attached below is the curve for probability of error as a function of alpha for strategy 2 for D1, D2, D3 and D4 datasets__\n",
    "\n",
    "![Figure: 3 - Probability of error as a function of alpha for Strategy 2 for all datasets](Strategy-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5104bcd3",
   "metadata": {},
   "source": [
    "### Observation and explanation:\n",
    "__In both the strategies both the probabilities of error for MLE is fixed which is expected as the MLE estimates are only dependent on the data.__\n",
    "\n",
    "__The probabilites of error in strategy 1 for Bayesian and MAP shows an increasing trend before saturating as the value of alpha increases. In Strategy 2, however, this trend is reversed and the probabilities of error reduces as alpha increases. However, after a certain value of alpha, the value is saturated and the saturation values for different datasets are the same in both the strategies. PoE is higher for smaller alpha in strategy 2 as shown in Figure 3. This trend is due to the fact that the prior information are different in both the strategies. When alpha is small, prior information has more weights. Strategy 2's prior information is worse as it provides the same mean value for both the classes whereas in strategy 1, different means are provided for foreground and background classes. This causes the Bayesian and MAP to be much worse off than MLE in strategy 2. As the alpha value increases, both Bayesian and MAP converge to MLE.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a143ca4a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb745a5b",
   "metadata": {},
   "source": [
    "# Equations used:\n",
    "\n",
    "![](Equations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5852de",
   "metadata": {},
   "source": [
    "# Matlab Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ccbab",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "clc;\n",
    "clear;\n",
    "close all;\n",
    "% Load training samples and alpha\n",
    "\n",
    "TrainingSet = load('hw3Data/TrainingSamplesDCT_subsets_8.mat');\n",
    "dataset_bg_1 = TrainingSet.D1_BG;\n",
    "dataset_fg_1 = TrainingSet.D1_FG;\n",
    "dataset_bg_2 = TrainingSet.D2_BG;\n",
    "dataset_fg_2 = TrainingSet.D2_FG;\n",
    "dataset_bg_3 = TrainingSet.D3_BG;\n",
    "dataset_fg_3 = TrainingSet.D3_FG;\n",
    "dataset_bg_4 = TrainingSet.D4_BG;\n",
    "dataset_fg_4 = TrainingSet.D4_FG;\n",
    "\n",
    "dataset_bg_list = {dataset_bg_1, dataset_bg_2, dataset_bg_3, dataset_bg_4};\n",
    "dataset_fg_list = {dataset_fg_1, dataset_fg_2, dataset_fg_3, dataset_fg_4};\n",
    "\n",
    "% Load alphas\n",
    "alpha = load('hw3Data/Alpha.mat');\n",
    "alpha = alpha.alpha; % Assing the alpha structure to the variable\n",
    "num_alpha = size(alpha, 2);\n",
    "\n",
    "% Load priors for 2 different strategies\n",
    "strategy_1 = load(\"hw3Data/Prior_1.mat\");\n",
    "strategy_2 = load(\"hw3Data/Prior_2.mat\");\n",
    "\n",
    "strategy_list = [strategy_1, strategy_2];\n",
    "\n",
    "pad_value = 7;\n",
    "cheetah = imread(\"../cheetah.bmp\");\n",
    "% cheetah = padarray(cheetah,[pad_value pad_value], 'post');\n",
    "% cheetah = im2double(cheetah);\n",
    "\n",
    "cheetah_scale = im2double(cheetah);\n",
    "cheetah_pad = zeros(size(cheetah_scale,1)+7,size(cheetah_scale,2)+7);\n",
    "cheetah_pad(3:257,3:272)=cheetah_scale;\n",
    "cheetah = cheetah_pad;\n",
    "\n",
    "[rows, cols] = size(cheetah);\n",
    "\n",
    "unpadded_rows = rows-pad_value;\n",
    "unpadded_cols = cols - pad_value;\n",
    "converted_block = zeros(unpadded_rows, unpadded_cols);\n",
    "zigzag = load(\"../Zig-Zag Pattern.txt\");\n",
    "zigzag = zigzag + 1; %Following MATLAB index\n",
    "\n",
    "true_image = imread('../cheetah_mask.bmp');\n",
    "\n",
    "for plan = 1:2 %Adding for scalability\n",
    "    strategy = strategy_list(plan);\n",
    "    figure;\n",
    "    for data = 1:4 %Adding for scalability\n",
    "        dataset_bg = dataset_bg_list(data);\n",
    "        dataset_fg = dataset_fg_list(data);\n",
    "\n",
    "        [bg_rows, bg_cols] = size(dataset_bg{1, 1});\n",
    "        [fg_rows, fg_cols] = size(dataset_fg{1, 1});\n",
    "\n",
    "        covar_bg = cov(dataset_bg{1, 1});\n",
    "        covar_fg = cov(dataset_fg{1, 1});\n",
    "        \n",
    "        mean_bg = mean(dataset_bg{1, 1});\n",
    "        mean_fg = mean(dataset_fg{1, 1});\n",
    "        error = [];\n",
    "        error_ML = [];\n",
    "        error_MAP = [];\n",
    "        subplot(2,2,data)\n",
    "        set(gcf,'Position', get(0, 'ScreenSize'))\n",
    "\n",
    "        for alpha_idx = 1:num_alpha\n",
    "            prior_sigma_0 = zeros(64,64);\n",
    "            for cov_idx=1:size(prior_sigma_0, 1)\n",
    "                prior_sigma_0(cov_idx, cov_idx) = alpha(alpha_idx) * strategy.W0(cov_idx);\n",
    "            end\n",
    "            \n",
    "            prior_background = bg_rows/(bg_rows + fg_rows);\n",
    "            prior_foreground = fg_rows/(fg_rows + bg_rows);\n",
    "            \n",
    "            % Bayesian BDR\n",
    "            % Background parameter distribution\n",
    "            inv_covar_bg = inv(covar_bg);\n",
    "            covar_bg_inter = inv(inv(prior_sigma_0) + bg_rows*inv(covar_bg));\n",
    "            covar_bg = covar_bg_inter+covar_bg;\n",
    "            inv_prior = inv(prior_sigma_0);\n",
    "            \n",
    "            mu_background_bayes = covar_bg_inter * (inv_prior*transpose(strategy.mu0_BG) + bg_rows*inv_covar_bg * transpose(mean_bg));\n",
    "            wi_background = inv(covar_bg);\n",
    "            determinant_background = det(covar_bg);\n",
    "\n",
    "            % Foreground parameter distribution\n",
    "            inv_covar_fg = inv(covar_fg);\n",
    "            covar_fg_inter = (inv(prior_sigma_0) + fg_rows*inv(covar_fg));\n",
    "            covar_fg_inter = inv(covar_fg_inter);\n",
    "            covar_fg = covar_fg_inter+covar_fg;\n",
    "            inv_prior = inv(prior_sigma_0);\n",
    " \n",
    "            mu_foreground_bayes = covar_fg_inter * (inv_prior*transpose(strategy.mu0_FG) + fg_rows*inv_covar_fg * transpose(mean_fg));\n",
    "            wi_foreground = inv(covar_fg);\n",
    "            determinant_foreground = det(covar_fg);\n",
    "\n",
    "            result_64 = zeros(unpadded_rows, unpadded_cols);\n",
    "\n",
    "            % Prediction with 64 dimensional gaussians\n",
    "            for i = 1:unpadded_rows\n",
    "                for j = 1:unpadded_cols\n",
    "                    block = cheetah(i:i+7, j:j+7);\n",
    "                    transform = dct2(block); \n",
    "                    % Create zigzag pattern\n",
    "                    zigzag_transform(zigzag) = transform;\n",
    "                    x = transpose(zigzag_transform);\n",
    "            \n",
    "                    % Cheetah\n",
    "                    exp_func = -0.5 * transpose(x-mu_foreground_bayes) * wi_foreground * (x-mu_foreground_bayes);\n",
    "                    exp_coeff = 1/(sqrt(((2*pi)^64) * determinant_foreground));\n",
    "                    p_y_x_cheetah = exp_coeff * exp(exp_func) * prior_foreground;\n",
    "            \n",
    "                    % Grass\n",
    "                    exp_func = -0.5 * transpose(x-mu_background_bayes) * wi_background * (x-mu_background_bayes);\n",
    "                    exp_coeff = 1/(sqrt(((2*pi)^64) * determinant_background));\n",
    "                    p_y_x_grass = exp_coeff * exp(exp_func) * prior_background;\n",
    "            \n",
    "                    if(p_y_x_cheetah > p_y_x_grass)\n",
    "                        result_64(i, j) = 1;\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "%             figure;\n",
    "%             imagesc(result_64);\n",
    "%             title('Prediction with 64 dimensions')\n",
    "%             colormap(gray(255));\n",
    "            error_tmp = calc_error(true_image, result_64, prior_foreground, prior_background);\n",
    "            error = [error error_tmp];\n",
    "        \n",
    "        \n",
    "            % Maximum Likelihood - BDR\n",
    "            covar_bg = cov(dataset_bg{1, 1});\n",
    "            covar_fg = cov(dataset_fg{1, 1});\n",
    "            \n",
    "            mean_bg = mean(dataset_bg{1, 1});\n",
    "            mean_fg = mean(dataset_fg{1, 1});\n",
    "            \n",
    "            result_64 = zeros(unpadded_rows, unpadded_cols);\n",
    "            mu_foreground = transpose(mean_fg);\n",
    "            mu_background = transpose(mean_bg);\n",
    "            determinant_foreground = det(covar_fg);\n",
    "            determinant_background = det(covar_bg);\n",
    "            wi_foreground = inv(covar_fg);\n",
    "            wi_background = inv(covar_bg);\n",
    "    \n",
    "            % Prediction with 64 dimensional gaussians\n",
    "            for i = 1:unpadded_rows\n",
    "                for j = 1:unpadded_cols\n",
    "                    block = cheetah(i:i+7, j:j+7);\n",
    "                    transform = dct2(block); \n",
    "                    % Create zigzag pattern\n",
    "                    zigzag_transform(zigzag) = transform;\n",
    "                    x = transpose(zigzag_transform);\n",
    "            \n",
    "                    % Cheetah\n",
    "                    exp_func = -0.5 * transpose(x-mu_foreground) * wi_foreground * (x-mu_foreground);\n",
    "                    exp_coeff = 1/(sqrt(((2*pi)^64) * determinant_foreground));\n",
    "                    p_y_x_cheetah = exp_coeff * exp(exp_func) * prior_foreground;\n",
    "            \n",
    "                    % Grass\n",
    "                    exp_func = -0.5 * transpose(x-mu_background) * wi_background * (x-mu_background);\n",
    "                    exp_coeff = 1/(sqrt(((2*pi)^64) * determinant_background));\n",
    "                    p_y_x_grass = exp_coeff * exp(exp_func) * prior_background;\n",
    "            \n",
    "                    if(p_y_x_cheetah > p_y_x_grass)\n",
    "                        result_64(i, j) = 1;\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            error_tmp = calc_error(true_image, result_64, prior_foreground, prior_background);\n",
    "            error_ML = [error_ML error_tmp];\n",
    "\n",
    "            % MAP - BDR\n",
    "            result_64 = zeros(unpadded_rows, unpadded_cols);\n",
    "            mu_background = mu_background_bayes;\n",
    "            mu_foreground = mu_foreground_bayes;\n",
    "            \n",
    "            % Prediction with 64 dimensional gaussians\n",
    "            for i = 1:unpadded_rows\n",
    "                for j = 1:unpadded_cols\n",
    "                    block = cheetah(i:i+7, j:j+7);\n",
    "                    transform = dct2(block); \n",
    "                    % Create zigzag pattern\n",
    "                    zigzag_transform(zigzag) = transform;\n",
    "                    x = transpose(zigzag_transform);\n",
    "            \n",
    "                    % Cheetah\n",
    "                    exp_func = -0.5 * transpose(x-mu_foreground) * wi_foreground * (x-mu_foreground);\n",
    "                    exp_coeff = 1/(sqrt(((2*pi)^64) * determinant_foreground));\n",
    "                    p_y_x_cheetah = exp_coeff * exp(exp_func) * prior_foreground;\n",
    "            \n",
    "                    % Grass\n",
    "                    exp_func = -0.5 * transpose(x-mu_background) * wi_background * (x-mu_background);\n",
    "                    exp_coeff = 1/(sqrt(((2*pi)^64) * determinant_background));\n",
    "                    p_y_x_grass = exp_coeff * exp(exp_func) * prior_background;\n",
    "            \n",
    "                    if(p_y_x_cheetah > p_y_x_grass)\n",
    "                        result_64(i, j) = 1;\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            error_tmp = calc_error(true_image, result_64, prior_foreground, prior_background);\n",
    "            error_MAP = [error_MAP error_tmp];\n",
    "        end \n",
    "\n",
    "        plot(alpha,error, alpha, error_ML, alpha, error_MAP);\n",
    "        legend('Predictive equation','Max-Likelihood Solution','MAP Solution');\n",
    "        set(gca, 'XScale', 'log');\n",
    "        title(['Probability of error vs Alpha: Dataset-', num2str(data)]);\n",
    "        xlabel('Alpha');\n",
    "        ylabel('Probability of error');\n",
    "\n",
    "\n",
    "    end\n",
    "\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "%------------------------- Helper functions ------------------------------%\n",
    "\n",
    "% Function to calculate the error\n",
    "function error = calc_error(ref_image, actual_image, p_fore, p_back)\n",
    "    foreground_pixels = 0;\n",
    "    background_pixels = 0;\n",
    "    \n",
    "    for i=1:size(ref_image, 1)\n",
    "        for j=1:size(ref_image, 2)\n",
    "            if ref_image(i, j) == 255\n",
    "                foreground_pixels = foreground_pixels + 1;\n",
    "            else\n",
    "                background_pixels = background_pixels + 1;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    foreground_error = 0;\n",
    "    background_error = 0;\n",
    "    for i=1:size(actual_image, 1)\n",
    "        for j=1:size(actual_image, 2)\n",
    "            if ref_image(i, j) == 255 && actual_image(i, j) == 0\n",
    "                foreground_error = foreground_error + 1;\n",
    "            elseif ref_image(i, j) == 0 && actual_image(i, j) == 1\n",
    "                background_error = background_error + 1;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    error_foreground = (foreground_error / foreground_pixels) * p_fore;\n",
    "    error_background = (background_error / background_pixels) * p_back;\n",
    "    error = (error_foreground + error_background);\n",
    "end\n",
    "\n",
    "% Function to calculate scalar Gaussian\n",
    "function prob_density = gaussian(x, u, sigma)\n",
    "        prob_density = (1/sqrt(2*pi*sigma*sigma) * exp(-(x-u).^2/(2*sigma.^2)));\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9154959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
